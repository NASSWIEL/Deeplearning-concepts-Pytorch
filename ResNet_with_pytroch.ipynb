{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8106d9",
   "metadata": {},
   "source": [
    "# PyTorch Linear Layers & ResNets Guide\n",
    "\n",
    "A beginner's guide to building neural networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce7a202",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook provides a practical guide to building neural networks with PyTorch, focusing on residual architectures and data handling pipelines.\n",
    "\n",
    "### Concepts Covered:\n",
    "\n",
    "1. **Imports** - Essential PyTorch libraries for building neural networks and handling data.\n",
    "2. **ResBlock (Module Class)** - A residual block with skip connections built using individual layer definitions.\n",
    "3. **ResBlock (Sequential)** - The same residual architecture implemented using `torch.nn.Sequential` for cleaner code.\n",
    "4. **ResNet** - A complete residual network combining multiple ResBlocks with nested skip connections.\n",
    "5. **Custom Dataset** - Creating a custom PyTorch Dataset class to generate and manage training data.\n",
    "6. **DataLoader** - Efficiently batching and loading data for training with shuffling and parallel workers.\n",
    "7. **Custom Sampler** - Implementing a custom sampling strategy to control how data is accessed during training.\n",
    "8. **Model Persistence** - Saving trained models to disk and loading them for inference or continued training.\n",
    "9. **Reproducibility** - Setting random seeds and deterministic algorithms to ensure consistent results across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24117acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184d4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acbfb691",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e68d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec7714",
   "metadata": {},
   "source": [
    "## 2. ResBlock Using Module Class\n",
    "\n",
    "Building a residual block with skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83700a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(torch.nn.Module):\n",
    "    \"\"\"Residual Block with skip connection\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=50, hiddens=[128, 32]):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hiddens = hiddens\n",
    "        \n",
    "        # Layers\n",
    "        self.ll1 = torch.nn.Linear(self.input_size, hiddens[0], bias=True)\n",
    "        self.leaky_relu = torch.nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.ll2 = torch.nn.Linear(self.hiddens[0], hiddens[1], bias=True)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.ll3 = torch.nn.Linear(self.hiddens[1], input_size, bias=True)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(input_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.ll1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.ll2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.ll3(x)\n",
    "        x += residual  # Skip connection\n",
    "        x = self.batch_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cebe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResBlock(\n",
      "  (ll1): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (ll2): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (ll3): Linear(in_features=5, out_features=20, bias=True)\n",
      "  (batch_norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize ResBlock\n",
    "resblock1 = ResBlock(20, [10, 5])\n",
    "print(resblock1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f7dd3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([100, 20])\n"
     ]
    }
   ],
   "source": [
    "# Test ResBlock\n",
    "data = torch.rand(100, 20)\n",
    "output = resblock1(data)\n",
    "print(f\"Output shape: {output.shape}\")  # Should be [100, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc4a13",
   "metadata": {},
   "source": [
    "## 3. ResBlock Using Sequential\n",
    "\n",
    "Same architecture using `torch.nn.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f60093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock2(torch.nn.Module):\n",
    "    \"\"\"ResBlock using Sequential\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=50, hiddens=[128, 32]):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.seq = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.input_size, hiddens[0], bias=True),\n",
    "            torch.nn.LeakyReLU(negative_slope=0.2),\n",
    "            torch.nn.Linear(hiddens[0], hiddens[1], bias=True),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(hiddens[1], input_size, bias=True)\n",
    "        )\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(input_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.seq(x)\n",
    "        x += residual\n",
    "        x = self.batch_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff94c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([100, 20])\n"
     ]
    }
   ],
   "source": [
    "# Test ResBlock2\n",
    "resblock2 = ResBlock2(20, [10, 5])\n",
    "output2 = resblock2(data)\n",
    "print(f\"Output shape: {output2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee0c1f",
   "metadata": {},
   "source": [
    "## 4. ResNet - Combining Multiple ResBlocks\n",
    "\n",
    "Architecture: `F(F(x)) + F(x) + x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8886bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(torch.nn.Module):\n",
    "    \"\"\"ResNet with two ResBlocks and multiple skip connections\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=50, hiddens=[128, 64]):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resblock1 = ResBlock(input_size, hiddens)\n",
    "        self.resblock2 = ResBlock2(input_size, hiddens)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.resblock1(x)      # F(x)\n",
    "        x2 = self.resblock2(x1)      # F(F(x))\n",
    "        output = x + x1 + x2         # x + F(x) + F(F(x))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b028e68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([100, 20])\n"
     ]
    }
   ],
   "source": [
    "# Initialize and test ResNet\n",
    "nnet = ResNet(20, [10, 5])\n",
    "random_data = torch.rand(100, 20)\n",
    "output_res = nnet(random_data)\n",
    "print(f\"Output shape: {output_res.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2dae2c",
   "metadata": {},
   "source": [
    "## 5. Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b89400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "    \"\"\"Generate random data with binary labels\"\"\"\n",
    "    \n",
    "    def __init__(self, num_samples=128, feature_dim=50):\n",
    "        self.len = num_samples\n",
    "        self.data = torch.randn(self.len, feature_dim)\n",
    "        self.labels = torch.randint(0, 2, (self.len,))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "406af42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([50])\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "dataset = RandomDataset()\n",
    "sample_data, sample_label = dataset[0]\n",
    "print(f\"Data shape: {sample_data.shape}\")\n",
    "print(f\"Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d589b",
   "metadata": {},
   "source": [
    "## 6. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda2c3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 16\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoader\n",
    "training_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Number of batches: {len(training_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9abbd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: data shape = torch.Size([8, 50]), target shape = torch.Size([8])\n",
      "Batch 1: data shape = torch.Size([8, 50]), target shape = torch.Size([8])\n",
      "Batch 2: data shape = torch.Size([8, 50]), target shape = torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# Test DataLoader\n",
    "for batch_idx, (data, target) in enumerate(training_loader):\n",
    "    print(f\"Batch {batch_idx}: data shape = {data.shape}, target shape = {target.shape}\")\n",
    "    if batch_idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe232ab",
   "metadata": {},
   "source": [
    "## 7. Custom Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6e4552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"Random sampler for dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, num_samples=128):\n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indices = torch.randperm(self.num_samples).tolist()\n",
    "        return iter(indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b35c3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use custom sampler\n",
    "sampler = RandomSampler(128)\n",
    "loader_with_sampler = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    sampler=sampler,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd328e9",
   "metadata": {},
   "source": [
    "## 8. Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcec091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Model loaded on cpu!\n",
      "Test output shape: torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save(nnet.state_dict(), 'resnet_model.pth')\n",
    "print(\"Model saved!\")\n",
    "\n",
    "# Load model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "loaded_model = ResNet(input_size=20, hiddens=[10, 5])\n",
    "loaded_model.load_state_dict(torch.load('resnet_model.pth', map_location=device))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "print(f\"Model loaded on {device}!\")\n",
    "\n",
    "# Test loaded model\n",
    "test_data = torch.rand(10, 20).to(device)\n",
    "with torch.no_grad():\n",
    "    output = loaded_model(test_data)\n",
    "print(f\"Test output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43417cd",
   "metadata": {},
   "source": [
    "## 9. Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04ec9cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reproducibility settings applied!\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "\n",
    "numpy.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# For deterministic algorithms\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "print(\"Reproducibility settings applied!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46247e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
